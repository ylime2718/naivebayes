{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b56d1e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "edbb4bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# My own simple feature extraction function\n",
    "def hashfeatures1(name,debug=False):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        name : a string representing the person's name to be hashed\n",
    "    \n",
    "    Output:\n",
    "        v: a feature vector representing the input string\n",
    "        v[0] = begins with vowel\n",
    "        v[1] = ends with vowel\n",
    "        v[2] = ends in 'a'\n",
    "        v[3] = ends in 'y'\n",
    "    \"\"\"\n",
    "    d = 4 # d: the number of dimensions to be in the feature vector\n",
    "    v = np.zeros(d)\n",
    "    \n",
    "    if name[0] == 'A' or name[0] == 'E' or name[0] == 'I' or name[0] == 'O' or name[0] == 'U' or name[0] == 'Y':\n",
    "        v[0] = 1\n",
    "    if name[-1] == 'a' or name[-1] == 'e' or name[-1] == 'i' or name[-1] == 'o' or name[-1] == 'u' or name[-1] == 'y':\n",
    "        v[1] = 1\n",
    "    if name[-1] == 'a':\n",
    "        v[2] = 1\n",
    "    if name[-1] == 'y':\n",
    "        v[3] = 1\n",
    "    if debug:\n",
    "        print(f\"Feature vector for {name}:\\n{v.astype(int)}\\n\")\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b91cb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function opens a file and calls the hashfeatures function on it to convert its contents into feature vectors\n",
    "def name2features(filename, d=128, FIX=3, LoadFile=True):\n",
    "    \"\"\"\n",
    "    Output:\n",
    "        X : n feature vectors of dimension d, (nxd)\n",
    "    \"\"\"\n",
    "    \n",
    "    # read in baby names\n",
    "    if LoadFile:\n",
    "        with open(filename, 'r') as f:\n",
    "            names = [x.rstrip() for x in f.readlines() if len(x) > 0]\n",
    "    else:\n",
    "        names = filename.split('\\n')\n",
    "    n = len(names)\n",
    "    X = np.zeros((n, d))\n",
    "    for i in range(n):\n",
    "        X[i,:] = hashfeatures1(names[i])\n",
    "    #print(X)\n",
    "    return (X, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b3e9e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "girlsTrain = \"GirlsTrain.txt\"\n",
    "boysTrain = \"BoysTrain.txt\"\n",
    "\n",
    "girlfeatures, numgirls = name2features(girlsTrain,4)\n",
    "girllabels = np.ones(numgirls) * -1\n",
    "boyfeatures, numboys = name2features(boysTrain,4)\n",
    "boylabels = np.ones(numboys)\n",
    "\n",
    "allLabels = np.concatenate([girllabels,boylabels])\n",
    "allfeatures = np.concatenate([girlfeatures,boyfeatures])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92f61dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naivebayesPY(X, Y):\n",
    "    \"\"\"\n",
    "    naivebayesPY(X, Y) returns [pos,neg]\n",
    "\n",
    "    Computation of P(Y)\n",
    "    Input:\n",
    "        X : n input vectors of d dimensions (nxd)\n",
    "        Y : n labels (-1 or +1) (nx1)\n",
    "\n",
    "    Output:\n",
    "        pos: probability p(y=1)\n",
    "        neg: probability p(y=-1)\n",
    "    \"\"\"\n",
    "    \n",
    "    # add one positive and negative example to avoid division by zero (\"plus-one smoothing\")\n",
    "    Y = np.concatenate([Y, [-1,1]])\n",
    "    n = len(Y)\n",
    "    arrsum = np.sum(Y)\n",
    "    \n",
    "    # SOLUTION - based on system of linear equations, solved for posCount with substitution\n",
    "    # arrSum = 1(posCount) - 1(negCount)\n",
    "    # n = posCount + negCount\n",
    "    \n",
    "    posCount = (n + arrsum)/2\n",
    "    \n",
    "    pos = (posCount)/n\n",
    "    neg = (n-posCount)/n\n",
    "    \n",
    "    #print(\"Probability of +1 is\",pos)\n",
    "    #print(\"Probability of -1 is\",neg)\n",
    "    return [pos,neg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "04b2c19a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4932084309133489, 0.506791569086651]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naivebayesPY(allfeatures,allLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad68289b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naivebayesPXY(X,Y):\n",
    "    \"\"\"\n",
    "    naivebayesPXY(X, Y) returns [posprob,negprob]\n",
    "    \n",
    "    Input:\n",
    "        X : n input vectors of d dimensions (nxd)\n",
    "        Y : n labels (-1 or +1) (n)\n",
    "    \n",
    "    Output:\n",
    "        posprob: probability vector of p(x_alpha = 1|y=1)  (d)\n",
    "            probability that feature d is 1 (true, or observed), given that the observed name is 1 (boy)\n",
    "        negprob: probability vector of p(x_alpha = 1|y=-1) (d)\n",
    "            probability that feature d is 1 (true, or observed), given that the observed name is 0 (girl)\n",
    "    \"\"\"\n",
    "    \n",
    "    # add one positive and negative example to avoid division by zero (\"plus-one smoothing\")\n",
    "    n, d = X.shape\n",
    "    X = np.concatenate([X, np.ones((2,d)), np.zeros((2,d))])\n",
    "    Y = np.concatenate([Y, [-1,1,-1,1]])\n",
    "    \n",
    "    # identify observations which are boys (slicing/indexing)\n",
    "    # count total number of boys\n",
    "    # across all of the d features, count the number of boy observations that are HOT, divide by total num of boys\n",
    "    \n",
    "    # I think this could be accomplished with just a sum, once I use some condtion on the Y vector (==1) to index the \n",
    "    # appropriate part of X\n",
    "    \n",
    "    # identify observations which are girls(slicing/indexing)\n",
    "    #print(X)\n",
    "    #print(Y)\n",
    "    \n",
    "    # Boys, Y=1\n",
    "    boys = X[Y == 1]\n",
    "    #print(boys)\n",
    "    b,d = boys.shape\n",
    "    #print(\"There are\",b,\"boys with\",d,\"features each\")\n",
    "    #Want to sum down the columns\n",
    "    boys_hot = np.sum(boys,axis=0)\n",
    "    #print(boys_hot)\n",
    "    posprob = boys_hot / b\n",
    "    #print(posprob)\n",
    "    \n",
    "    # Girls, Y=-1\n",
    "    girls = X[Y == -1]\n",
    "    g,d = girls.shape\n",
    "    #print(\"There are\",g,\"girls with\",d,\"features each\")\n",
    "    girls_hot = np.sum(girls,axis=0)\n",
    "    negprob = girls_hot / g\n",
    "    \n",
    "    return [posprob,negprob]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5b927315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.19639469, 0.29601518, 0.01802657, 0.07305503]),\n",
       " array([0.26592798, 0.72299169, 0.37026777, 0.10710988])]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naivebayesPXY(allfeatures,allLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72434cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loglikelihood(posprob, negprob, X_test, Y_test):\n",
    "    \"\"\"\n",
    "    loglikelihood(posprob, negprob, X_test, Y_test) returns loglikelihood of each point in X_test\n",
    "    \n",
    "    Input:\n",
    "        posprob: conditional probabilities for the positive class (d)\n",
    "        negprob: conditional probabilities for the negative class (d)\n",
    "        X_test : features (nxd)\n",
    "        Y_test : labels (-1 or +1) (n)\n",
    "    \n",
    "    Output:\n",
    "        loglikelihood of each point in X_test (n)\n",
    "    \"\"\"\n",
    "    \n",
    "    # BOYS\n",
    "    # Y = +1\n",
    "    boys = X_test[Y_test == 1]\n",
    "    b,d = boys.shape\n",
    "    \n",
    "    # GIRLS\n",
    "    # Y = -1\n",
    "    girls = X_test[Y_test == -1]\n",
    "    #print(girls)\n",
    "    g,d = girls.shape\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a7e9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naivebayes_pred(pos, neg, posprob, negprob, X_test):\n",
    "    \"\"\"\n",
    "    naivebayes_pred(pos, neg, posprob, negprob, X_test) returns the prediction of each point in X_test\n",
    "    \n",
    "    Input:\n",
    "        pos: class probability for the negative class\n",
    "        neg: class probability for the positive class\n",
    "        posprob: conditional probabilities for the positive class (d)\n",
    "        negprob: conditional probabilities for the negative class (d)\n",
    "        X_test : features (nxd)\n",
    "    \n",
    "    Output:\n",
    "        prediction of each point in X_test (n)\n",
    "    \"\"\"\n",
    "    # call loglikelihood to find two points of comparison.\n",
    "    llp,lln = loglikelihood(posprob, negprob, X_test)\n",
    "    \n",
    "    # add class prior probability to each of the P(x|Y) vectors\n",
    "    llp = llp + pos\n",
    "    lln = lln + neg\n",
    "    \n",
    "    # TO DO: compare llp and lln element-wise, returning class of the maximum between the two\n",
    "    \n",
    "    # Notes:\n",
    "    # Instead of loglikelihood returning a 2-tuple of nx1 vectors, it could return an nx2 vector, which would make it\n",
    "    # easier to make the final prediction (use np.argmax). It would mean adding the class prior probability would\n",
    "    # be slightly more complicated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2467d051",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
