{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b453ba2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1fdcb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From Cornell course CIS532 project content:\n",
    "# Purpose of function is to convert a name into a feature vector\n",
    "def hashfeatures(baby, d, FIX, debug=False):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        baby : a string representing the baby's name to be hashed\n",
    "        \n",
    "        d: the number of dimensions to be in the feature vector\n",
    "        \n",
    "        FIX: the number of chunks to extract and hash from each string\n",
    "        \n",
    "        debug: a bool for printing debug values (default False)\n",
    "    \n",
    "    Output:\n",
    "        v: a feature vector representing the input string\n",
    "    \"\"\"\n",
    "    \n",
    "    v = np.zeros(d)\n",
    "    for m in range(1, FIX+1):\n",
    "        prefix = baby[:m] + \">\"\n",
    "        P = hash(prefix) % d\n",
    "        v[P] = 1\n",
    "        \n",
    "        suffix = \"<\" + baby[-m:]\n",
    "        S = hash(suffix) % d\n",
    "        v[S] = 1\n",
    "        \n",
    "        if debug:\n",
    "            print(f\"Split {m}/{FIX}:\\t({prefix}, {suffix}),\\t1s at indices [{P}, {S}]\")\n",
    "    if debug:\n",
    "        print(f\"Feature vector for {baby}:\\n{v.astype(int)}\\n\")\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "133a571a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From Cornell course CIS532 project content:\n",
    "def name2features(filename, d=128, FIX=3, LoadFile=True, debug=False):\n",
    "    \"\"\"\n",
    "    Output:\n",
    "        X : n feature vectors of dimension d, (nxd)\n",
    "    \"\"\"\n",
    "    \n",
    "    # read in baby names\n",
    "    if LoadFile:\n",
    "        with open(filename, 'r') as f:\n",
    "            babynames = [x.rstrip() for x in f.readlines() if len(x) > 0]\n",
    "    else:\n",
    "        babynames = filename.split('\\n')\n",
    "    n = len(babynames)\n",
    "    X = np.zeros((n, d))\n",
    "    for i in range(n):\n",
    "        X[i,:] = hashfeatures(babynames[i], d, FIX)\n",
    "    return (X, babynames) if debug else X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1631e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From Cornell course CIS532 project content:\n",
    "# TO DO: to recreate/generate boys.train and girls.train files before running this code\n",
    "\n",
    "\"\"\"\n",
    "Xboys, namesBoys = name2features(\"boys.train\", d=128, FIX=3, debug=True)\n",
    "Xgirls, namesGirls = name2features(\"girls.train\", d=128, FIX=3, debug=True)\n",
    "X = np.concatenate([Xboys[:20], Xgirls[:20]], axis=0)\n",
    "\n",
    "plt.figure(figsize=(20, 8))\n",
    "ax = sns.heatmap(X.astype(int), cbar=False)\n",
    "ax.set_xlabel('feature indices')\n",
    "ax.set_ylabel('baby names')\n",
    "ticks = ax.set_yticks(np.arange(40, dtype=int))\n",
    "ticklabels = ax.set_yticklabels(namesBoys[:20] + namesGirls[:20])\n",
    "plt.show()\n",
    "\"\"\"\n",
    "\n",
    "# Certain feature vectors might be white for many names because (1) many names have that feature in common or \n",
    "# (2) there are hash collisions occurring due to an insufficiently large d value.\n",
    "\n",
    "def genTrainFeatures(dimension=128):\n",
    "    \"\"\"\n",
    "    Input: \n",
    "        dimension: desired dimension of the features\n",
    "    Output: \n",
    "        X: n feature vectors of dimensionality d (nxd)\n",
    "        Y: n labels (-1 = girl, +1 = boy) (n)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load in the data\n",
    "    Xgirls = name2features(\"girls.train\", d=dimension)\n",
    "    Xboys = name2features(\"boys.train\", d=dimension)\n",
    "    X = np.concatenate([Xgirls, Xboys])\n",
    "    \n",
    "    # Generate Labels\n",
    "    Y = np.concatenate([-np.ones(len(Xgirls)), np.ones(len(Xboys))])\n",
    "    \n",
    "    # shuffle data into random order\n",
    "    ii = np.random.permutation([i for i in range(len(Y))])\n",
    "    \n",
    "    return X[ii, :], Y[ii]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7def3c3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nX, Y = genTrainFeatures(128)\\nprint(f'Shape of training data: {X.shape}')\\nprint(f'X:\\n{X.astype(int)}')\\nprint(f'Y:\\n{Y.astype(int)}')\\n\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# From Cornell course CIS532 project content:\n",
    "\"\"\"\n",
    "X, Y = genTrainFeatures(128)\n",
    "print(f'Shape of training data: {X.shape}')\n",
    "print(f'X:\\n{X.astype(int)}')\n",
    "print(f'Y:\\n{Y.astype(int)}')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b4be2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MY CODE\n",
    "def naivebayesPY(X, Y):\n",
    "    \"\"\"\n",
    "    naivebayesPY(X, Y) returns [pos,neg]\n",
    "\n",
    "    Computation of P(Y)\n",
    "    Input:\n",
    "        X : n input vectors of d dimensions (nxd)\n",
    "        Y : n labels (-1 or +1) (nx1)\n",
    "\n",
    "    Output:\n",
    "        pos: probability p(y=1)\n",
    "        neg: probability p(y=-1)\n",
    "    \"\"\"\n",
    "    \n",
    "    # add one positive and negative example to avoid division by zero (\"plus-one smoothing\")\n",
    "    Y = np.concatenate([Y, [-1,1]])\n",
    "    n = len(Y)\n",
    "    arrsum = np.sum(Y)\n",
    "    \n",
    "    # SOLUTION - based on system of linear equations, solved for posCount with substitution\n",
    "    # arrSum = 1(posCount) - 1(negCount)\n",
    "    # n = posCount + negCount\n",
    "    \n",
    "    posCount = (n + arrsum)/2\n",
    "    \n",
    "    pos = (posCount)/n\n",
    "    neg = (n-posCount)/n\n",
    "    \n",
    "    #print(\"Probability of +1 is\",pos)\n",
    "    #print(\"Probability of -1 is\",neg)\n",
    "    return [pos,neg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "523f7cbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5555555555555556, 0.4444444444444444]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tests for naivesbayesPY\n",
    "testY1 = np.array([-1,1,-1,1,-1,1,1]) # one more +1 than -1, so sum will be +1\n",
    "naivebayesPY(testY1, testY1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4859b413",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4, 0.6]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testY2 = np.array([-1,-1,1]) # one more -1 than +1, so sum will be -1\n",
    "naivebayesPY(testY2, testY2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3688339e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8, 0.2]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testY3 = np.array([1,1,1]) # one more -1 than +1, so sum will be -1\n",
    "naivebayesPY(testY3, testY3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dcf2d180",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naivebayesPXY(X,Y):\n",
    "    \"\"\"\n",
    "    naivebayesPXY(X, Y) returns [posprob,negprob]\n",
    "    \n",
    "    Input:\n",
    "        X : n input vectors of d dimensions (nxd)\n",
    "        Y : n labels (-1 or +1) (n)\n",
    "    \n",
    "    Output:\n",
    "        posprob: probability vector of p(x_alpha = 1|y=1)  (d)\n",
    "            probability that feature d is 1 (true, or observed), given that the observed name is 1 (boy)\n",
    "        negprob: probability vector of p(x_alpha = 1|y=-1) (d)\n",
    "            probability that feature d is 1 (true, or observed), given that the observed name is 0 (girl)\n",
    "    \"\"\"\n",
    "    \n",
    "    # add one positive and negative example to avoid division by zero (\"plus-one smoothing\")\n",
    "    n, d = X.shape\n",
    "    X = np.concatenate([X, np.ones((2,d)), np.zeros((2,d))])\n",
    "    Y = np.concatenate([Y, [-1,1,-1,1]])\n",
    "    \n",
    "    # identify observations which are boys (slicing/indexing)\n",
    "    # count total number of boys\n",
    "    # across all of the d features, count the number of boy observations that are HOT, divide by total num of boys\n",
    "    \n",
    "    # I think this could be accomplished with just a sum, once I use some condtion on the Y vector (==1) to index the \n",
    "    # appropriate part of X\n",
    "    \n",
    "    # identify observations which are girls(slicing/indexing)\n",
    "    #print(X)\n",
    "    #print(Y)\n",
    "    \n",
    "    # Boys, Y=1\n",
    "    boys = X[Y == 1]\n",
    "    #print(boys)\n",
    "    b,d = boys.shape\n",
    "    #print(\"There are\",b,\"boys with\",d,\"features each\")\n",
    "    #Want to sum down the columns\n",
    "    boys_hot = np.sum(boys,axis=0)\n",
    "    #print(boys_hot)\n",
    "    posprob = boys_hot / b\n",
    "    #print(posprob)\n",
    "    \n",
    "    # Girls, Y=-1\n",
    "    girls = X[Y == -1]\n",
    "    g,d = girls.shape\n",
    "    #print(\"There are\",g,\"girls with\",d,\"features each\")\n",
    "    girls_hot = np.sum(girls,axis=0)\n",
    "    negprob = girls_hot / g\n",
    "    \n",
    "    return [posprob,negprob]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "08d1007a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1.25, 1.25, 1.25]), array([1.4, 1.4, 1.4])]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test for naivebayesPXY\n",
    "testX = np.array([[0,0,0],[1,1,1],[2,2,2],[3,3,3],[4,4,4]])\n",
    "testY = np.array([-1,1,-1,1,-1])\n",
    "naivebayesPXY(testX,testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "81d5f000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nX, Y = genTrainFeatures(128)\\nposprob, negprob = naivebayesPXY(X, Y)\\nprobs = pd.DataFrame({'feature': np.arange(128, dtype=int), 'boys': posprob, 'girls': negprob})\\n\\nplt.figure(figsize=(20, 4))\\nax = sns.lineplot(x='feature', y='value', hue='variable', data=pd.melt(probs, ['feature']))\\nax.set_xlabel('feature indices')\\nax.set_ylabel('probability')\\nplt.show()\\n\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "X, Y = genTrainFeatures(128)\n",
    "posprob, negprob = naivebayesPXY(X, Y)\n",
    "probs = pd.DataFrame({'feature': np.arange(128, dtype=int), 'boys': posprob, 'girls': negprob})\n",
    "\n",
    "plt.figure(figsize=(20, 4))\n",
    "ax = sns.lineplot(x='feature', y='value', hue='variable', data=pd.melt(probs, ['feature']))\n",
    "ax.set_xlabel('feature indices')\n",
    "ax.set_ylabel('probability')\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d58b3133",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loglikelihood(posprob, negprob, X_test, Y_test):\n",
    "    \"\"\"\n",
    "    loglikelihood(posprob, negprob, X_test, Y_test) returns loglikelihood of each point in X_test\n",
    "    \n",
    "    Input:\n",
    "        posprob: conditional probabilities for the positive class (d)\n",
    "        negprob: conditional probabilities for the negative class (d)\n",
    "        X_test : features (nxd)\n",
    "        Y_test : labels (-1 or +1) (n)\n",
    "    \n",
    "    Output:\n",
    "        loglikelihood of each point in X_test (n)\n",
    "    \"\"\"\n",
    "    \n",
    "    # BOYS\n",
    "    # Y = +1\n",
    "    boys = X_test[Y_test == 1]\n",
    "    b,d = boys.shape\n",
    "    \n",
    "    # GIRLS\n",
    "    # Y = -1\n",
    "    girls = X_test[Y_test == -1]\n",
    "    #print(girls)\n",
    "    g,d = girls.shape\n",
    "    \n",
    "    # QUESTION - doesn't each point get 2 probabilities, so we can compare the probability of a name being \n",
    "    # boy vs girl?\n",
    "    # QUESTION - where do these labels come from? I thought the test points didn't have labels?\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2e0d20b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naivebayes_pred(pos, neg, posprob, negprob, X_test):\n",
    "    \"\"\"\n",
    "    naivebayes_pred(pos, neg, posprob, negprob, X_test) returns the prediction of each point in X_test\n",
    "    \n",
    "    Input:\n",
    "        pos: class probability for the negative class\n",
    "        neg: class probability for the positive class\n",
    "        posprob: conditional probabilities for the positive class (d)\n",
    "        negprob: conditional probabilities for the negative class (d)\n",
    "        X_test : features (nxd)\n",
    "    \n",
    "    Output:\n",
    "        prediction of each point in X_test (n)\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "05a28155",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nDIMS = 128\\nprint(\\'Loading data ...\\')\\nX,Y = genTrainFeatures(DIMS)\\nprint(\\'Training classifier ...\\')\\npos, neg = naivebayesPY(X, Y)\\nposprob, negprob = naivebayesPXY(X, Y)\\nerror = np.mean(naivebayes_pred(pos, neg, posprob, negprob, X) != Y)\\nprint(\\'Training error: %.2f%%\\' % (100 * error))\\n\\nwhile True:\\n    print(\\'Please enter a baby name (press enter with empty box to stop prompt)>\\')\\n    yourname = input()\\n    if len(yourname) < 1:\\n        break\\n    xtest = name2features(yourname,d=DIMS,LoadFile=False)\\n    pred = naivebayes_pred(pos, neg, posprob, negprob, xtest)\\n    if pred > 0:\\n        print(\"%s, I am sure you are a baby boy.\\n\" % yourname)\\n    else:\\n        print(\"%s, I am sure you are a baby girl.\\n\" % yourname)\\n'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "DIMS = 128\n",
    "print('Loading data ...')\n",
    "X,Y = genTrainFeatures(DIMS)\n",
    "print('Training classifier ...')\n",
    "pos, neg = naivebayesPY(X, Y)\n",
    "posprob, negprob = naivebayesPXY(X, Y)\n",
    "error = np.mean(naivebayes_pred(pos, neg, posprob, negprob, X) != Y)\n",
    "print('Training error: %.2f%%' % (100 * error))\n",
    "\n",
    "while True:\n",
    "    print('Please enter a baby name (press enter with empty box to stop prompt)>')\n",
    "    yourname = input()\n",
    "    if len(yourname) < 1:\n",
    "        break\n",
    "    xtest = name2features(yourname,d=DIMS,LoadFile=False)\n",
    "    pred = naivebayes_pred(pos, neg, posprob, negprob, xtest)\n",
    "    if pred > 0:\n",
    "        print(\"%s, I am sure you are a baby boy.\\n\" % yourname)\n",
    "    else:\n",
    "        print(\"%s, I am sure you are a baby girl.\\n\" % yourname)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6247708a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def name2features2(filename, d=128, FIX=3, LoadFile=True):\n",
    "    \"\"\"\n",
    "    Output:\n",
    "        X : n feature vectors of dimension d, (nxd)\n",
    "    \"\"\"\n",
    "    # read in baby names\n",
    "    if LoadFile:\n",
    "        with open(filename, 'r') as f:\n",
    "            babynames = [x.rstrip() for x in f.readlines() if len(x) > 0]\n",
    "    else:\n",
    "        babynames = filename.split('\\n')\n",
    "    n = len(babynames)\n",
    "    X = np.zeros((n, d))\n",
    "    for i in range(n):\n",
    "        X[i,:] = hashfeatures(babynames[i], d, FIX)\n",
    "        \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b59e1af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
